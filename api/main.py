"""
FastAPI —Å–µ—Ä–≤–∏—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–∞–π—Ç–æ–≤
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Supabase –∏ –∞–¥–∞–ø—Ç–∞—Ü–∏—è —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –ª–æ–≥–∏–∫–∏
"""

import asyncio
import logging
import os
import sys
from datetime import datetime
from typing import Dict, Any, Optional
import uvicorn
from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel, Field
# import jwt  # –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–æ
# from playwright.async_api import async_playwright  # –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–æ

# –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–ª–∞–¥–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
print("Starting AI Researcher Console API...")
try:
    print(f"Python path: {sys.path}")
    print(f"Current working directory: {os.getcwd()}")
    print(f"Files in current directory: {os.listdir('.')}")
except Exception as e:
    print(f"Debug info error: {e}")

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∫–æ–¥—É  
sys.path.insert(0, '/app')
sys.path.insert(0, '/app/src')

# –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º —Å–ª–æ–∂–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
# from src.pipelines.classification_pipeline import EnhancedPipeline
# from src.analyzers.ai_analyzer import MultiStageAnalyzer
# from src.scrapers.content_scraper import smart_fetch_content
# import config.settings as config
# from prompt_manager import initialize_prompt_manager, get_prompt_manager

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
app = FastAPI(
    title="AI Researcher Console API",
    description="API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤–µ–±-—Å–∞–π—Ç–æ–≤",
    version="1.0.0"
)

# CORS –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –¥–æ–º–µ–Ω–∞–º–∏
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
security = HTTPBearer()

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class AnalysisRequest(BaseModel):
    domain: str = Field(..., description="–î–æ–º–µ–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    url: str = Field(..., description="URL –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
    profile_type: str = Field(..., description="–¢–∏–ø –ø—Ä–æ—Ñ–∏–ª—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

class AnalysisResponse(BaseModel):
    domain: str
    classification: str
    confidence: float
    comment: str
    processing_time: float
    raw_data: Dict[str, Any]

class HealthResponse(BaseModel):
    status: str
    timestamp: str
    version: str

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
# pipelines: Dict[str, EnhancedPipeline] = {}
# browser_context = None

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–∞)
# async def initialize_pipelines():
#     """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–æ–≤ –¥–ª—è –≤—Å–µ—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π"""
#     global pipelines
#     
#     profiles = [
#         'software', 'iso', 'telemedicine', 'pharma', 'edtech', 'marketing',
#         'fintech', 'healthtech', 'elearning', 'software_products',
#         'salesforce_partner', 'hubspot_partner', 'aws', 'shopify',
#         'ai_companies', 'mobile_app', 'recruiting', 'banking', 'platforms'
#     ]
#     
#     for profile in profiles:
#         try:
#             pipelines[profile] = EnhancedPipeline(profile=profile)
#             logger.info(f"Initialized pipeline for profile: {profile}")
#         except Exception as e:
#             logger.error(f"Failed to initialize pipeline for {profile}: {e}")

# async def initialize_browser():
#     """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±—Ä–∞—É–∑–µ—Ä–∞"""
#     global browser_context
#     
#     try:
#         playwright = await async_playwright().start()
#         browser = await playwright.chromium.launch(
#             headless=True,
#             args=['--disable-dev-shm-usage', '--no-sandbox']
#         )
#         browser_context = await browser.new_context(
#             user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
#         )
#         logger.info("Browser initialized successfully")
#     except Exception as e:
#         logger.error(f"Failed to initialize browser: {e}")
#         raise

# –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω—ã)
# async def get_pipeline(profile_type: str) -> EnhancedPipeline:
#     """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è"""
#     if profile_type not in pipelines:
#         raise HTTPException(status_code=400, detail=f"Unsupported profile type: {profile_type}")
#     return pipelines[profile_type]

def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)) -> Dict[str, Any]:
    """–í–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è JWT —Ç–æ–∫–µ–Ω–∞ (–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–∞)"""
    # –í—Ä–µ–º–µ–Ω–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
    return {"user_id": "test", "role": "admin"}

# API endpoints
@app.get("/health", response_model=HealthResponse)
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–∏—Å–∞"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –æ—Å–Ω–æ–≤–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        status = "healthy"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        required_env_vars = ["GOOGLE_API_KEY"]
        missing_vars = [var for var in required_env_vars if not os.getenv(var)]
        
        if missing_vars:
            status = "degraded"
            logger.warning(f"Missing environment variables: {missing_vars}")
        
        return HealthResponse(
            status=status,
            timestamp=datetime.now().isoformat(),
            version="1.0.0"
        )
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return HealthResponse(
            status="unhealthy",
            timestamp=datetime.now().isoformat(),
            version="1.0.0"
        )

@app.post("/analyze", response_model=AnalysisResponse)
async def analyze_website(
    request: AnalysisRequest,
    token_data: Dict[str, Any] = Depends(verify_token)
    # pipeline: EnhancedPipeline = Depends(get_pipeline)  # –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–æ
):
    """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –≤–µ–±-—Å–∞–π—Ç–∞ (–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω)"""
    
    # –í—Ä–µ–º–µ–Ω–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
    return AnalysisResponse(
        domain=request.domain,
        classification="Service temporarily unavailable",
        confidence=0.0,
        comment="Analysis service is being initialized",
        processing_time=0.0,
        raw_data={"status": "initializing"}
    )

@app.post("/analyze-batch")
async def analyze_batch(
    requests: list[AnalysisRequest],
    background_tasks: BackgroundTasks,
    token_data: Dict[str, Any] = Depends(verify_token)
):
    """–ê–Ω–∞–ª–∏–∑ –±–∞—Ç—á–∞ –≤–µ–±-—Å–∞–π—Ç–æ–≤ (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)"""
    
    if len(requests) > 100:  # –õ–∏–º–∏—Ç –Ω–∞ —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
        raise HTTPException(status_code=400, detail="Batch size too large (max 100)")
    
    # –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –≤ —Ñ–æ–Ω–µ
    background_tasks.add_task(process_batch_analysis, requests, token_data)
    
    return {
        "message": f"Batch analysis started for {len(requests)} websites",
        "batch_id": f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    }

async def process_batch_analysis(requests: list[AnalysisRequest], token_data: Dict[str, Any]):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ –∞–Ω–∞–ª–∏–∑–æ–≤ –≤ —Ñ–æ–Ω–µ (–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–∞)"""
    
    logger.info(f"Batch analysis requested for {len(requests)} websites")
    logger.info("Batch processing temporarily disabled - returning mock results")
    
    # –í—Ä–µ–º–µ–Ω–Ω–∞—è –∑–∞–≥–ª—É—à–∫–∞
    results = []
    errors = []
    
    for request in requests:
        # –ú–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        results.append({
            "domain": request.domain,
            "result": {
                "classification": "Service temporarily unavailable",
                "confidence": 0.0,
                "comment": "Batch processing is being initialized",
                "processing_time": 0.0
            }
        })
    
    logger.info(f"Mock batch analysis completed: {len(results)} processed")
    return {"results": results, "errors": errors}

@app.get("/profiles")
async def get_available_profiles():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ—Ñ–∏–ª–µ–π"""
    return {
        "profiles": ["software", "fintech", "edtech", "healthtech"],
        "descriptions": {
            "software": "–ü—Ä–æ–≥—Ä–∞–º–º–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã –∏ SaaS —Ä–µ—à–µ–Ω–∏—è",
            "fintech": "–§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
            "edtech": "–û–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
            "healthtech": "–ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏"
        },
        "status": "Service temporarily in minimal mode"
    }

@app.get("/prompts")
async def get_prompts(
    profile_type: str = None,
    prompt_type: str = None,
    token_data: Dict[str, Any] = Depends(verify_token)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ (–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–æ)"""
    
    return {"prompts": [], "status": "Service temporarily unavailable"}

@app.post("/prompts")
async def create_prompt(
    prompt_data: Dict[str, Any],
    token_data: Dict[str, Any] = Depends(verify_token)
):
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ (–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–æ)"""
    
    return {"status": "Service temporarily unavailable"}

@app.put("/prompts/{prompt_id}")
async def update_prompt(
    prompt_id: str,
    update_data: Dict[str, Any],
    token_data: Dict[str, Any] = Depends(verify_token)
):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ (–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–æ)"""
    
    return {"status": "Service temporarily unavailable"}

@app.post("/prompts/{prompt_id}/set-default")
async def set_default_prompt(
    prompt_id: str,
    token_data: Dict[str, Any] = Depends(verify_token)
):
    """–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–æ–º–ø—Ç–∞ –∫–∞–∫ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–æ)"""
    
    return {"status": "Service temporarily unavailable"}

# –°–æ–±—ã—Ç–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
    try:
        logger.info("Starting AI Researcher Console API...")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        port = os.getenv("PORT", "8000")
        environment = os.getenv("ENVIRONMENT", "development")
        
        logger.info(f"Environment: {environment}")
        logger.info(f"Port: {port}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è Google API –∫–ª—é—á–µ–π
        google_key = os.getenv("GOOGLE_API_KEY")
        if google_key:
            logger.info("Google API key found")
        else:
            logger.warning("Google API key not found - some features will be disabled")
        
        logger.info("API initialized successfully (minimal mode)")
        print("‚úÖ API startup completed successfully")
        
    except Exception as e:
        logger.error(f"Startup error: {e}")
        print(f"‚ùå API startup failed: {e}")
        raise

@app.on_event("shutdown")
async def shutdown_event():
    """–û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏"""
    logger.info("Shutting down AI Researcher Console API...")

# –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞
if __name__ == "__main__":
    try:
        port = int(os.getenv("PORT", 8000))
        host = os.getenv("HOST", "0.0.0.0")
        environment = os.getenv("ENVIRONMENT", "development")
        
        print(f"üöÄ Starting AI Researcher Console API")
        print(f"   Host: {host}")
        print(f"   Port: {port}")
        print(f"   Environment: {environment}")
        print(f"   Working Directory: {os.getcwd()}")
        
        uvicorn.run(
            "main:app",
            host=host,
            port=port,
            reload=environment == "development",
            log_level="info"
        )
        
    except Exception as e:
        print(f"‚ùå Failed to start server: {e}")
        import traceback
        traceback.print_exc()
        raise
